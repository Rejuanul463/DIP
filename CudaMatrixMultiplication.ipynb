{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoxFaaYc5okYujrs3SBEyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rejuanul463/DIP/blob/main/CudaMatrixMultiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Guyr2U9_G3h",
        "outputId": "cb82c637-f459-48c1-8d25-a0abb74bd66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cudaMatrix.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cudaMatrix.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matrixMul(float* A, float* B, float* C, int M, int N, int P, int offset) {\n",
        "    int k = threadIdx.x + offset;\n",
        "\n",
        "    float* a = A + k * M * N;\n",
        "    float* b = B + k * N * P;\n",
        "    float* c = C + k * M * P;\n",
        "\n",
        "    for(int i = 0; i < M; i++) {\n",
        "        for(int j = 0; j < N; j++) {\n",
        "            for(int l = 0; l < P; l++) {\n",
        "                //c[i][l] += a[i][j] * b[j][l];\n",
        "                c[i * P + l] = a[i * N + j] * b[j * P + l];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    int T = atoi(argv[1]); //koyta thread use korte parbo\n",
        "    int K = atoi(argv[2]); //koita matrix gun\n",
        "\n",
        "    //100 gun, thread 10,\n",
        "\n",
        "    int M = 400, N = 400, P = 400;\n",
        "\n",
        "    int SizeA = M * N * K;\n",
        "    int SizeB = N * P * K;\n",
        "    int SizeC = M * P * K;\n",
        "\n",
        "    //memory alocate (cpu allocate) HOST\n",
        "    float *h_A = new float[SizeA];\n",
        "    float *h_B = new float[SizeB];\n",
        "    float *h_C = new float[SizeC];\n",
        "\n",
        "\n",
        "    //malloc (gpu allocate) Device\n",
        "    float *d_A;\n",
        "    cudaMalloc(&d_A, SizeA * sizeof(float));\n",
        "    float *d_B;\n",
        "    cudaMalloc(&d_B, SizeB * sizeof(float));\n",
        "    float *d_C;\n",
        "    cudaMalloc(&d_C, SizeC * sizeof(float));\n",
        "\n",
        "    //data initialize\n",
        "    for (int i = 0; i < SizeA; i++) {\n",
        "        h_A[i] = rand();\n",
        "    }\n",
        "    for(int i = 0; i < SizeB; i++) {\n",
        "        h_B[i] = rand();\n",
        "    }\n",
        "\n",
        "\n",
        "    //copy from host to device\n",
        "    cudaMemcpy(d_A, h_A, SizeA * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, SizeB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    //cuda process suru\n",
        "    int gunKorteHobe = K;\n",
        "    int offset = 0;\n",
        "    while(gunKorteHobe > 0){\n",
        "\n",
        "        int currentBatch = min(gunKorteHobe, T);\n",
        "\n",
        "        matrixMul<<<1,currentBatch>>>(d_A, d_B, d_C, M, N, P, offset);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        gunKorteHobe -= currentBatch;\n",
        "        offset += currentBatch;\n",
        "    }\n",
        "\n",
        "    //let's copy back to cpu\n",
        "    cudaMemcpy(h_C, d_C, SizeC * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"All operation done\" << endl;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cudaMatrix.cu -o matrixMultiplication"
      ],
      "metadata": {
        "id": "R96VOWvS_26N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./matrixMultiplication 1 10 && sleep 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuvHqosc_3RW",
        "outputId": "0e3640f3-9d7f-4c7f-9551-0d7a48d9e5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All operation done\n",
            "\n",
            "real\t0m29.997s\n",
            "user\t0m29.554s\n",
            "sys\t0m0.235s\n"
          ]
        }
      ]
    }
  ]
}